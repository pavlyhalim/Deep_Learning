# Project 5: ROUGE-L Score, LLM Inference Benchmarking, and Dialogue Summarization

This project has three parts. The first part implements the ROUGE-L score for evaluating LLM-generated summaries. The second part benchmarks LLM inference using vLLM, a high-performance inference engine, and analyzes the impact of different parameters on inference speed. The third part fine-tunes a generative AI model for dialogue summarization.

## Topics Covered

*   ROUGE-L Score
*   LLM Summarization Evaluation
*   LLM Inference Benchmarking
*   vLLM
*   Dialogue Summarization
*   Parameter Efficient Fine-Tuning (PEFT)
*   Low-Rank Adaptation (LoRA)